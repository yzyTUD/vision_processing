

    done:
        //
            basic functions
            opencv integration
            skybox integration
            boxgui_v2 imp
            simple mesh loader/renderer, be able to work with openmesh.
            implicit surface extraction of dense field
            implement fusion algorithms with implicit surface
            a testbed for point cloud registration algorithms
            steam home like interactions
            gen. some point clouds to test 
            loading two or more clouds 
            boxgui UI controller switch support 
            clipping useless points 
            draw points and generate faces: with simple_mesh, 
                can I draw one face with multiple points not in a plane?
                quick test: vec3(1,1,0),vec3(1,-1,0),vec3(-1,1,0),vec3(-1,-1,-1)
                et 4h 
            hands-on: model fitting demo 
                rendering and generating of the quads or ... 
            controllable downscale rendering
                use a bbox to identify range in full scale 
            create faces with simple mesh 
            right button down for confirm -> trigger to confirm 
            hmbgui: handhold menu bar 
            add timestemp as file name
            ok-make cgv building blocks: skybox, merge vr_pc_processing piecewise
            ok-boxgui_v2
            ok-effecient rendering of point clouds   
            https://www.youtube.com/watch?v=ulVTcpOtiQQ
            ok-define clipping plane  

        goal 
            object modeling hq 
            trianle + para surface 
                //+ lowpoly 
            + 
                pcl/ OnlineSurfaceRecon/ 
                Feature Point 

            0. point cloud processing 
            1. face extraction 
                rg 
                direct mark 
            2. edge extraction: 
                rg -> egde 
                covex 
                direct 
                visual control 
                p: 
                    an other region growing? 
                    fitting? 
            3. corner 
                direct fitting
                pcl based 

            4. connective graph extraction 

            5. rendering 
                color 
                texture 
    
    totest: 
        //
            selection tool 
                render a ball in front 
                draw boundary directly 
            clipping tool 
            selection ICP -calibration algos ICP! adjest current frame only with preves frame! 
                merge 
                consider go-icp and sparce icp 
                choose space and then calibrate only in this area 
                    subsample the points in a ball with controller 
            UI in vr to start cam  
            port region growing to interactable 
                perform again 
            seed init, class generation 
            mark of boundaries 
    
    skipped:
        //
            skip-clod rendering, basic culling with gl 
                et 4h 
            skip-mark boundary with controllers and force to stop at boundaries
                et nh 
            later-camera set 3d printed
                design 
                    et 3h 
            poisson recon 
                not accurate 
            skip-more effecient rendering of the points serfels: clod rendering 
            skip-quick test on cloud rendering 
                merege the clod rendering 
                with Fenek renderer 
            later-physics support 
            quick test pcl/other libs feature functions for point clouds 
    
    todo/req:
        f: rendering effeciency: 
            <2.0ms when empty load, <2.5ms when clipping everything 
            should show green with steamvr 
                (
                    good frame time and bad frame time
                    all frames should be marked as green
                    
                )
        performance issue when compared to IMEngine 
            glGenBuffers(GL_ARRAY_BUFFER,)
            glBufferData(BufferTargets[type], totalSize, data, GL_DYNAMIC_DRAW);
            s1: use vao/vbos directly
            s3: remove the "set_position_array"
            s2: split into chunks 
        core workflow: 
            point cloud editing support in vr 
                group/ color picker
                add deletion support: at least for vertices 
                mark as deleted, check when rendering 
                    like skip in drawable 
                addition is also strightfow.
            parallel support 
            clean code 
            group info? group transformation? 
            write faces/meshes/... to files 
            port old functions to current framework, from vr_scanning, depre. 
                rgbd camera related ... 
                marking 
                region growing 
                ...
            reading: learn fitting functions in a obj or similar file, fit to surface/ plane 
                et 4h 
        gui 
            import point clouds with gui? 
            fix gui stuff, support infinite btns 
            load images, image panel 
            load dir within vr 
        in vr:  
            click a point and set it as floor, fixed transformation translate 
            correct starting pose of the rgbd cam 
        effecient:
            parallel processing support 
            more effecient/ enhancement in draw calls 
    
    todo/req:(old) 
        trival stuffs:    
        //
        scanning setup
            https://www.thingiverse.com/thing:2083915
            meshmixer 
            vision based (opencv 
                https://rdmilligan.wordpress.com/2016/05/15/epipolar-geometry-and-depth-map-from-stereo-images/
                https://docs.opencv.org/3.1.0/da/de9/tutorial_py_epipolar_geometry.html#gsc.tab=0
        //
        Scanning to pcs 
            pc calibration with icp variants, or sift
            *normal estimation approach 
            mcmc method helps 
            *provide user interaction to guide registration algorithm
        ////
            other modes:
                new points generated (below) (math parameters as output)
                feature point based cube generation, plane generation (triangles as output)
                delauney triangulation/ poission reconstruction (triangles as output)
                volumn based methods (triangles as output)
        ////
            region growing 
                read the code pc_view 
                point normal computing and visualization
                *mark and *grows marked regions 
                    grow a simple region 
                    fix the mesh loader in cgv, load and correct mesh 
                        openmesh rendering 
                    normal information are used and can be smoothed interactively 
                *provide user interaction to control grow speed 
            feature extraction, local features
                https://link.springer.com/article/10.1007/s00371-008-0223-2
                from sgumhold:
                    Input: point cloud with per point face index
                    Output: connectivity graph of base mesh with vertices, edges, faces and incidence/adjacency information
                    Algorithm:
                        1.create one mesh face for each face index in the point cloud and assign all points with this face index to the face
                        2.point classification: for each point use knn graph and collect all face indices of neighbors. Classify point into
                            a.interior, if all face indices are identical
                            b.boundary, if two different face indices arise
                            c.corner otherwise, number of different face indices is called valence of point
                        3.corner extraction: traverse corner points in order of decreasing valence. Starting with each such reference corner point do region growing with knn neighborgraph on points and stop if you find non corner point or corner point whose face indices are not subset of face indices of reference point. Assign all collected points to a newly created mesh vertex and remove points from traversal. Add vertex-face incidences to all mesh faces of the encountered face indices.
                        4.edge extraction: iterate all boundary points. For each boundary point do region growing of neighboring points that are boundary points with respect to same pair of face indices. Create new mesh edge and assign all extracted points to edge. Add edge-face incidences to data structure
                        5.split edges into half edges and determine origin, next and inv pointers of half-edge data structure from vertex-face and edge-face incidences stored before
                    
                    There are some details in the algorithm missing that deals with surface boundaries but I hope that the general idea becomes clear.
                    
                    You end up with a mesh, where each vertex, edge and face has a set of points assigned to it. In the last step you can fit positions to the points of a vertex, curves to the points of an edge and surfaces to the points of a face.
            deal with outliers and holes
                extrapolation 
            //
            surface fitting  
                +
                    fit to parametrized surfaces 
                    fitting helps to reduce the scanning noise

                task:: fit with given points 
            // 
            generate, output, rendering 
                +
                    parametrized surface visualization 
                    triangulation, resampling 
                    sample/ render a plane surface from cg1 
                    from stefan
                        the first level 
                            individual 3D scans / depth images are stored one per file. Each line specifies on point:
                            i j x y z nx ny nz r g b
                            here i and j are indices in the depth images.
                        The second level stores connectivity information and references the scan files. 
                            First it lists scan files with one file per line:
                                s file_name
                            This assigns one index for each file where indices should start with 1.
                            Per vertex one specifies one line:
                                v f1 k1 f2 k2 …
                            where f1 f2 … are file indices and k1 k2 … are the point indices inside of the file. 
                            Point indices should also start with 1. The listed points are the ones that are assigned to the vertex 
                            in the interactive tool at the end of the region growing process

                            Per edge one would specify a line
                                e v1 v2 f1 k1 f2 k2 …
                            with v1 v2 the indices (starting with 1) of the two vertices connected together by the edge 
                                or two times 0 if the edge is closed and is not incident to a vertex.
                            The pairs f1 k1 f2 k2 … again specify the points in the 3d scans that are assigned to the edge
                            
                            Per face one would specify a line
                                f n e1 e2 e3 … en f1 k1 f2 k2 …
                            where n is the number of edges in the face loop e1 … en are the edges in the face loop 
                                and  the pairs f1 k1 f2 k2 … again specify the points in the 3d scans that are assigned to the face
                        The third level would store fitting information in a third file or at the end of the second level file. With one line per vertex:
                            V x y z [nx, ny, nz]
                            Specifying the fitted location and optionally a surface normal in case of a smooth vertex.
                            Per Edge
                            E …
                            Information to represent a curve. For example four control point positions for a Bezier curve
                            F …
                            Information to represent a surface. For example 16 control point positions for a Bezier surface patch plus optionally trimming curves for each edge in uv parameter domain.
                    render with bezier surface pitches 
                        https://www.web3d.org/documents/specifications/19775-1/V3.3/Part01/components/nurbs.html
                        http://vis.berkeley.edu/~joshea/images/bez5b.png
                        http://vis.berkeley.edu/~joshea/projects/bezier/
                        http://vis.berkeley.edu/~joshea/projects/shapefromshading/
                        http://vis.berkeley.edu/~joshea/projects/subdivision/
                        https://visualizationlibrary.org/documentation/pag_guide_bezier_surfaces.html
                        https://visualizationlibrary.org/docs/2.0/gallery/bezier01.jpg
                        Making 3D Solids from Surface Data
                        Bezier datas made by Martin Newell.
                        http://en.wikipedia.org/wiki/Utah_teapot
                        we can also view it externally so far 
                        https://blog.demofox.org/2014/03/09/implicit-vs-parametric-vs-explicit-surfaces/
                        Bezier Surface Properties?

                ref::https://visualizationlibrary.org/documentation/pag_guide_bezier_surfaces.html     
                    read the code 
                task::generate surfaces that can be read by VL 
        ////
        Labeling, Animating 
            rigid body integration 
            rigging integration 
            assign materials 
    
    future oomi work:  
        loading of datasets 
            https://www.semantic3d.net/

        feature extraction from point clouds, deep learning approach 
        region growing algorithms 
        3d reconstruction algorithms
        surface playground 
        animating playground
    
    what do we have?
        pc support: 
            point_cloud_vr library 
        region growing support 
            from sgumhold surf_rec application 
        mesh support: 
            mesh editing tool by vr_mesh_view proj
            inhirtance to modify simple_mesh  
        surface fitting support: 
            ...
        pinocchio support: 
            pinocchio library (no additional dependency)
        
