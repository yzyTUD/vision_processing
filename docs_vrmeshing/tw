
    ---
    mixed background/ MA/ master thesis 
        basic concepts:
            matching: find correspondences
            bring 3D scans in same coordinate  system
            fusion: merge partial scans
            point filtering
            estimate globally  consistent surface
            Delaunay-Tetrahedralization
            Robust  and fast implementations in CGAL  or qhull. 
            convex hull
        cg2_slides 
            build neighbourgrouph 
                Riemannian-Graph: directed 
                symmetrized Riemannian-Graph: no direction 
            Outlier filter 
                In not symmetrized RiemannianGraph most edges of 
                    an outlier  point are outgoing and only few  ingoing 
            sampling density estimation 
                sampling density ? is defined  as the minimum radius of a circle  in tangential space
                Sampling density typically  varies over surface
                can be estimeted from average  distance to 3rd up to sixth nearest  
                    neighbor points. 
            Tangent Space Estimation, normal computation 
                optimization problem
                    Linear least squares
                    basic localization weighting
                Iterated Re-weightes Least Squares, IRLS fitting 
                    solves the discontinuities problem 
                bilateral fitting 
                    couple the local optimzation
                        problems into a global, nonlinear optimization problem
                globally consistent normal 
                position of 3D scanner defines outside direction
                typically this is done by building neighbor graph and propagate
                    normal orientation along graph edges
            compute curvature
                use the tailor series of ğ‘”(ğ‘¥, ğ‘¦) around the 2D origin to
                    compute the curvature properties
                Solve with weighted pseudo inverse or with SVD
                https://dl.acm.org/doi/pdf/10.5555/601671.601673
            feature detection/ modification  
                https://www.researchgate.net/publication/2554207_Feature_Extraction_from_Point_Clouds
                what feature can be expected 
                    corner
                    sharp corner 
                    close sheets
                    edges 
                    faces 
                Spin images 
                    can well distinguish different
                    local surface types
                denoising 
                    https://dl.acm.org/doi/pdf/10.1145/882262.882368
                    https://dl.acm.org/doi/pdf/10.1145/882262.882367
                control the density 
        effecient rendering of point clouds 
            https://www.researchgate.net/profile/Soeren_Discher/publication/325619805_A_Point-Based_and_Image-Based_Multi-Pass_Rendering_Technique_for_Visualizing_Massive_3D_Point_Clouds_in_VR_Environments/links/5b191550aca272021ceed577/A-Point-Based-and-Image-Based-Multi-Pass-Rendering-Technique-for-Visualizing-Massive-3D-Point-Clouds-in-VR-Environments.pdf
                Virtual reality  (VR) applications rely on high frame rates (i.e., around 90 fps as opposed to 30 - 60 fps) and show high sensitivity  to any kind of visual artifacts
                combined using a multipass rendering pipeline
                s containing up to 2.6 billion points to show the practicability and scalability of our approach.
                granting users  the perception of being physically present in a 3D virtual environment
                For complex sites, e.g., buildings with a highly detailed  interior, or large areas
                a Airborne scan of a city.
                Terrestrial indoor scan
                measuring of distances as well as rotating and scaling of the  rendered data
                s light detection and ranging (LiDAR)
                precision rates of  up to a few centimeters or millimeters
                unmanned aircraft systems (UAS)
                hundreds of gigabytes of raw data
                Large unstructured collections of 3D points
                In VR  applications additional challenges are raised
                has to be rendered for two displays  simultaneously
                tend to be more noticeable on VR displays,  can easily break the immersion
                update after a physical movement by the user, becomes too high
                the built-in displays of VR devices such as Oculus  Rift or HTC Vive operate at 90 Hz
                frames have to be rendered at a considerably higher  speed compared to non-immersive applications
                widely used in a variety of geospatial [9] and non-geospatial applications
                out-of-core rendering
                spatial data structures
                subdivide 3D point clouds into small, representative subsets  that are suitable for real-time rendering.
                view frustum culling
                portal culling
                Culling techniques used to reduce the amount  of points to be rendered: View frustum culling (yellow),  occlusion culling (orange), detail culling (red). 
                Data subset selection, point cloud rendering, and image-based postprocessing. 
                Data Subset Selection
                subsets are determined on a per-frame basis
                points are aggregated based on their spatial position to  accommodate for the perspective distortion resulting in  areas farther away from the current view position to appear smaller on screen
                detail culling
                For each 3D point cloud a separate  kd-tree is generated in a preprocessing step.
                Paraboloid Rendering
                Paraboloid rendering is a technique introduced by  Sché»·z
                aims to further reduce visual clutter  by rendering points not as flat
                Close-up view
                Multisampling
                provides  a smoother color transition between neighboring  fragments by sampling them several times
                Measurements on an Oculus Rift lead to comparable, slightly better results due to the tighter view  frustum. T
                cyclic overlap
                piercing polygons.
                https://hal.inria.fr/hal-01348404v2/document
            https://www.vrvis.at/publications/pdfs/PB-VRVis-2019-008.pdf
                Discrete LOD structure with sudden jumps in density and popping artifacts under motion
                No visible seams across different levels of detail due to a continuous reduction in density
                https://www.mdpi.com/2072-4292/12/14/2224/htm
                hierarchically organized  chunks with varying extent and density
                which results in sudden  changes of density from one level of detail to another
                We propose a continuous level-of-detail method that exhibits gradual rather than sudden changes in density
                . Our method continuously  recreates a down-sampled vertex buffer from the full point cloud,  based on camera orientation, position, and distance to the camera
                The improved acceptance  of our method was successfully evaluated in a user study.
                the lack of mipmapping
                whereas scans of large areas and whole countries may  consist of hundreds of billions of points. 
                hierarchical acceleration structures are used in order  to efficiently load and render these amounts of data
                in-core rendering of data sets that fit in GPU memory, but which  are still too large to be rendered in real time in VR
                As the distance to the viewer increases,  the density of the chunks to be rendered decreases
                Chunk-wise  handling of LODs has emerged as the state of the art
                coarse-grained management of data reduces overhead on file I/O,
                The disadvantage, however, is that these  chunks are noticeable in the rendered image, especially at lower  levels of detail and during motion.
                Progressive Rendering
            https://www.cg.tuwien.ac.at/research/publications/2017/FRAISS-2017-PCU/
            Fast Out-of-Core Octree Generation for Massive Point Clouds
                https://www.cg.tuwien.ac.at/research/publications/2020/SCHUETZ-2020-MPC/SCHUETZ-2020-MPC-paper.pdf
            Efficient Loading and Visualization of Massive Feature-Richt Point Clouds Without Hierarchical Acceleration Structures
                https://www.cg.tuwien.ac.at/research/publications/2020/OTEPKA-2020-PPC/OTEPKA-2020-PPC-paper.pdf
            Progressive Real-Time Rendering of One Billion Points Without Hierarchical Acceleration Structures
                https://github.com/m-schuetz/skye
                https://www.cg.tuwien.ac.at/research/publications/2020/schuetz-2020-PPC/schuetz-2020-PPC-paper.pdf
            [2018 sig]Progressive Real-Time Rendering of Unprocessed Point Clouds
                https://dl.acm.org/doi/pdf/10.1145/3230744.3230816
        judge if point included effeciently 
            imp. in vertex shader 
        GPU related stuffs 
            https://zhuanlan.zhihu.com/p/61358167
                CPUçš„æµæ°´çº¿è¾ƒé•¿ï¼Œæ§åˆ¶å™¨è¾ƒä¸ºå¤æ‚ï¼Œè®¡ç®—è¶‹äºçº¿æ€§æ‰§è¡Œï¼ˆå¯éƒ¨åˆ†å¹¶è¡Œï¼‰
                CPUå†…éƒ¨ALUæ•°é‡è¾ƒå°‘ï¼Œæ‰€ä»¥ä¸é€‚åˆåšæ•°å€¼è®¡ç®—å¯†é›†å‹çš„æ•°å­¦è®¡ç®—ã€‚
                GPUçš„æµæ°´çº¿å¾ˆçŸ­ï¼Œæ§åˆ¶å™¨è¾ƒä¸ºç®€å•ï¼Œå†…éƒ¨é›†æˆäº†å¤§é‡ALU
                å¯å¹¶è¡Œæ‰§è¡Œçš„æ•°å­¦è®¡ç®—æŠ›ç»™GPUæ‰§è¡Œï¼ˆä¾‹å¦‚ï¼Œå›¾åƒå¤„ç†ã€è§†é¢‘ç¼–è§£ç ã€ç‰©ç†ç²’å­è®¡ç®—ç­‰
                å«åšæ˜¾å­˜ï¼ˆVRAMï¼‰
                æäº¤æ¸²æŸ“æ•°æ®æ—¶ï¼Œå°½é‡æ‰¹é‡æäº¤ï¼Œå‡å°‘CPUå‘GPUæäº¤æ•°æ®æ¬¡æ•°
                å°½é‡é¿å…ä»GPUå›è¯»æ•°æ®ï¼Œè¿™æ ·å¯ä»¥å‡å°‘ä¸¤è€…æ•°æ®äº¤äº’ã€‚
                GPUè¢«åˆ’åˆ†æˆå¤šä¸ªGPCs(Graphics Processing Cluster)
                é¿å…åœ¨shaderä¸­ä½¿ç”¨if elseï¼šå› ä¸ºæŒ‰ç…§SIMDçš„æ‰§è¡Œæ–¹å¼ï¼Œif elseå¯èƒ½ä¼šå®Œå…¨ä¸ç”Ÿæ•ˆï¼Œå¯¼è‡´ä¸¤ä¸ªåˆ†æ”¯éƒ½è¦èµ°ä¸€éã€‚åŒæ ·å¾ªç¯ä¸­çš„breakä¹Ÿä¼šå¯¼è‡´è¿™æ ·çš„é—®é¢˜ã€‚
                Compute shaderæ˜¯ä¸€ä¸ªé€šç”¨çš„ç€è‰²å™¨ï¼Œå®ƒä½¿ç”¨åœ¨æ¸²æŸ“ç®¡çº¿ä¹‹å¤–ï¼Œå³å®ƒä¸æ˜¯ç”¨æ¥ç»˜åˆ¶ä¸€ä¸ªå›¾å…ƒæˆ–æ¸²æŸ“åƒç´ çš„ã€‚é‚£å®ƒæ˜¯ç”¨ä¸ä»€ä¹ˆçš„å‘¢ï¼ŸCompute shaderåˆ©ç”¨GPUsçš„å¹¶è¡Œè®¡ç®—å¤„ç†èƒ½åŠ›æ¥åšé€šç”¨è®¡ç®—ä»»åŠ¡
                ç”±vertex shader å®Œæˆã€‚è¾“å…¥ä¸è¾“å‡ºä¸€ä¸€å¯¹åº”ï¼Œå³ä¸€ä¸ªé¡¶ç‚¹è¢«å¤„ç†åä»ç„¶æ˜¯ä¸€ä¸ªé¡¶ç‚¹ï¼Œå„é¡¶ç‚¹é—´çš„å¤„ç†ç›¸äº’ç‹¬ç«‹
                å¯ä»¥å¹¶è¡Œ
        point cloud alignment, registration 
            sum:
                the least correspondences points would be? 
                    3 
                correspondences can be? 
                    point-to-point, point-2-plane, line-to-line 
                icp assumes the crspds are estimated, not given as input 

            slides 
                icp algorithm
                    features are points, lines, planes 
                    registration of 3d scans 
                    find a rigid transformation 
                kabsch algorithm 
                    solve a eqution and a rigid transformation will be generated 
                see pics 
            course codes 
                err-https://igl.ethz.ch/projects/ARAP/svd_rot.pdf
                correct-https://ieeexplore.ieee.org/document/88573
                http://hua-zhou.github.io/teaching/biostatm280-2017spring/slides/16-eigsvd/eigsvd.html
            
                1. taken as heuristic, error!, full matching can only work as exact match
                    for the same object! 
                    > mesh feature computes correctly
                    > for further use (checking)
                2. local minima can be partially cured by re set min val 
                3. feature can not compute iteratiely, may cause eror when not accurate, even 1e-7
                4. feature matching can be done randomly, with out considering distance 
                
            https://en.wikipedia.org/wiki/Iterative_closest_point
            MeshLab 
                manually select feature points 
                https://www.youtube.com/watch?v=jAXAxQvX8Cc          
            2013, Go-ICP: Solving 3D Registration Efficiently and Globally Optimally
                http://jlyang.org/iccv13_go-icp.pdf
            2016, Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration
                http://jlyang.org/tpami16_go-icp_preprint.pdf
                https://github.com/yangjiaolong/Go-ICP
                ICP is however well-known to  suffer from local minima.
                combines it with a branch-and-bound (BnB)  scheme
                outlier robustness
                The concept of ICP is simple and intuitive. 
                    It alternates between estimating geometric transformation 
                    (rotation and translation), and estimating the 
                    point-wise correspondences
                widely used in computer vision, and beyond computer vision
                ICP is however also well-known for its suffering from  
                    the issue of local minima
                Despite that this drawback of local-minima is generally well-known, 
                    relatively few papers have tackled this issue explicitly
            2019, A Symmetric Objective Function for ICP
                https://gfx.cs.princeton.edu/pubs/Rusinkiewicz_2019_ASO/symm_icp.pdf
            [2020]Point Cloud Registration Algorithm Based on the Grey Wolf Optimizer.
                https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9159580
            [2020]Evaluation of the ICP Algorithm in 3D Point Cloud Registration
                https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9060927
            [2020]Color Point Cloud Registration Based on Supervoxel Correspondence
                https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950119
            [2017]https://www.ipb.uni-bonn.de/pdfs/foerstner17efficient.pdf
        Curvature computation and map to colors!  
            https://www.researchgate.net/publication/333418053_Efficient_Curvature_Estimation_for_Oriented_Point_Clouds
            https://pdf.sciencedirectassets.com/282073/1-s2.0-S2212017314X00022/1-s2.0-S2212017313006828/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGUaCXVzLWVhc3QtMSJGMEQCIEytzKIS%2BNBW5fYKf4%2BTfzK6aLy8Ga2yxhjQnkJ6T16xAiB%2Fp%2BpkXgzSsoZhe5zJhCIZhSU67fXevr4NI74DC6MVdSq0AwgeEAMaDDA1OTAwMzU0Njg2NSIM1CpVmUNR7Lufz9ScKpEDuJIXS7QH6RWH8kEtEDaAk1jJu0SImAnxiPfR9qaVJomryfzXgef2JbLV%2FaHYlfxdFC3wmz6ZwW9%2BklhNY37sb9g0XWVfQzRdCSCvAu1aLSrGj6hIpdVSwIoS6O4HqMh1t9jPU6jAlQPDLrpeZ6N3w6FSQTQlR6uHNz59sGoOGmhPyaBvJuRfYSmxtvptpHASes%2Bsd3vs1jWS5HKiFdDUKfTg81UJPYtwu%2FB4STVzJ0KfdTL1asHjRUQfEbwhlhy%2FwsiD0FCDe1xuNX5Xp8ftrdwG480r7emNnpjj8AEJJHf9Yg5VUFtMKQGV%2FpswMRHlfX7qNbMwbryi2NbXrvswqWDw5X0AE4u%2FEY49tU8aOkCIh9dtrCCKTkma437%2FOQYXsJZtm6JWrOiPebJIDNXP8c91TyPIICQBXoZ24ddb0SLq90XusAtU4s2FPJzxIRFPlElAkxwmK4q%2FuSEz47l1idJV%2Ba84eOIHY7dtJ3lpL%2BcYVaXRXzKmBemLDyQlZWljK1yJSaw1GQH4xFn0zea6Mkcwnbme%2FwU67AHxLxFEprNLy5oqoN7dWM6evUyaEzwMANPWTksr7JMvFmxlZEUkyWMm9zjdaSMAop6%2Fe2SqbwpIWuSOPLTkrZio0KUZWyQLd%2B6Lc9aOZpo%2B9n9IP8WxZFj0GIwcHWwcx%2FHX1pgW%2FI%2BDB1YHK2gTD9VIhUF5xujkSZkNon1l16rwo6Pgo0AV7qaiA5RdMG1NsdhNXY2LvxkAFXxlxBMlZotO1qRXmAcPNfV6byP8dbMxDugLx7GwwLdawS%2F0EMKcSsU1uuyBBZrcwjE%2FWK62CGiYl7EIXmpBjLAOy%2BX8RZwpCud3qwkI3XBXZeSKcA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20201226T211739Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY34VWLATM%2F20201226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=0fd6a1a78d07d8e21431ee93a3719f7b94924cd1b1874883e7f5f0f4fb155a77&hash=fe91f390a754eb723d9cd6b03b6b8b794549292b6c4e5873bfae4b9d8e6d4397&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2212017313006828&tid=spdf-2b4cb487-93c8-4dc9-9091-2d6546a8693d&sid=90e05b5c4f34d543f37bf661f070dfb0a7bdgxrqb&type=client
            http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0405/MUIR/av-2.html
            
            https://github.com/alecjacobson/geometry-processing-curvature
            http://gts.sourceforge.net/darcs/gts-devel/src/curvature.c
            https://libigl.github.io/tutorial/#gaussian-curvature

            https://blenderartists.org/t/addon-mesh-curvature-to-vertex-colors/641381/3
        region growing:
            https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-3-W10/153/2020/isprs-archives-XLII-3-W10-153-2020.pdf
            https://www.ais.uni-bonn.de/papers/IAS_2012_Holz.pdf
            https://core.ac.uk/download/pdf/141884213.pdf
        feature extraction, local features:
            the generating file format 
        surface fitting:
        generate, output, rendering: reconstruction 
            https://hal.inria.fr/hal-01348404v2/document
            https://www.mdpi.com/2072-4292/12/14/2224/htm
        Labeling, semantic segmenation 
        deeplearning on point clouds (future work)
            https://arxiv.org/pdf/1912.12033.pdf
        scanning besed modeling pipeline
            build nighbourgrouph 
                Riemannian-Graph: directed 
                symmetrized Riemannian-Graph: no direction 
            Outlier filter 
                In not symmetrized RiemannianGraph most edges of 
                    an outlier  point are outgoing and only few  ingoing 
            sampling density estimation 
                sampling density ? is defined  as the minimum radius of a circle  in tangential space
                Sampling density typically  varies over surface
                can be estimeted from average  distance to 3rd up to sixth nearest  
                    neighbor points. 
            Tangent Space Estimation, normal computation 
                optimization problem
                    Linear least squares
                    basic localization weighting
                Iterated Re-weightes Least Squares, IRLS fitting 
                    solves the discontinuities problem 
                bilateral fitting 
                    couple the local optimzation
                        problems into a global, nonlinear optimization problem
                globally consistent normal 
                position of 3D scanner defines outside direction
                typically this is done by building neighbor graph and propagate
                    normal orientation along graph edges
            compute curvature
                use the tailor series of ğ‘”(ğ‘¥, ğ‘¦) around the 2D origin to
                    compute the curvature properties
                Solve with weighted pseudo inverse or with SVD
                https://dl.acm.org/doi/pdf/10.5555/601671.601673
            feature detection/ modification  
                https://www.researchgate.net/publication/2554207_Feature_Extraction_from_Point_Clouds
                what feature can be expected 
                    corner
                    sharp corner 
                    close sheets
                    edges 
                    faces 
                Spin images 
                    can well distinguish different
                    local surface types
                denoising 
                    https://dl.acm.org/doi/pdf/10.1145/882262.882368
                    https://dl.acm.org/doi/pdf/10.1145/882262.882367
                control the density 
        modeling
        cad 
        spline 
        region growing 
        triangulation 
        3d printing 
            gcode generation, slicing 
            adjestment  
                height adjestment 
                temp. 
                    pingtai
        the support of spline in obj format 

    ---
    pointclouds -> semantic
        topic: point cloud reduction/ processing/ feature extraction/ rendering 
            preview 
                https://github.com/Yochengliu/awesome-point-cloud-analysis
                pcl 
                    https://pcl.readthedocs.io/projects/tutorials/en/latest/pcl_visualizer.html
                    p: pc operations?
                    p: quick test? 
                        with a cmake project
                        make it private repo todo 
                    https://pcl.readthedocs.io/projects/tutorials/en/latest/walkthrough.html#walkthrough
                what is local features?
                    estimated from local near points 
                    characterize a point using the information provided by its k closest point neighbors
                what are spatial decomposition techniques? 
                    usually split into smaller chunks using spatial decomposition techniques such as octrees or kD-trees
                
            *features? 
                ok-map surface normal to color 
                colorize points by curvature 
                edge/corner detection 
                    https://arxiv.org/ftp/arxiv/papers/1809/1809.10468.pdf
                keypoints
                    3D-SIFT 
                    NARF keypoints


            keyword
                pointcloud cleaning tool 
            hands-on 
                https://github.com/charlesq34/pointnet
                
            devices 
                Leica BLK360 

            approaches 
                +deep learning approaches 
                [2016] PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation
                    https://web.stanford.edu/~rqi/pointnet/
                    https://github.com/charlesq34/pointnet
                [2016] Potree: Rendering Large Point Clouds in Web Browsers
                    https://www.cg.tuwien.ac.at/research/publications/2016/SCHUETZ-2016-POT/SCHUETZ-2016-POT-thesis.pdf
                [2019] Feature-Preserving Simplification of Point Cloud by Using Clustering Approach Based on Mean Curvature
                    https://art-science.org/journal/v14n4/v14n4pp117/artsci-v14n4pp117.pdf
            stru 

    --- 
    pointclouds -> meshes
        
        topic: surface reconstruction from [point clouds]
            
            hands-on tools/ inspire:
                soft:
                    cloudcompare 
                        Poisson recon with point clouds 
                    meshlab 
                        pointclouds feed in 
                    meshroom 
                        https://meshroom-manual.readthedocs.io/en/latest/node-reference/nodes/Texturing.html
                        ...
                    RealityCapture 
                        https://www.youtube.com/watch?v=-CwdugODkmQ
                        in a combined method 
                        works! * 
                    Recap Photo
                        mesh as input? 
                    blender 
                        https://www.youtube.com/watch?v=h01fZH1eu0k
                        https://en.wikibooks.org/wiki/Blender_3D:_Noob_to_Pro/UV_Map_Basics
                        https://www.youtube.com/watch?v=2b64oeC6wKg
                        https://blenderartists.org/t/merging-dense-mesh-obj-into-single-mesh-keeping-texture-mapping/1203923
                        ...
                    Cinema 4D  
                        https://3dscanexpert.com/3d-scan-uv-texture-remap-c4d/ 
                    geometryhub
                        uv unfolding 
                    artec recon texturing 

                coding libs:
                    cloudcompare
                        further plugins? 
                    pcl 
                    libigl 
                    cgal 
                        https://doc.cgal.org/latest/Manual/tuto_reconstruction.html

                    pcl 
                    mvs
                        may supported in meshroom 
                        https://github.com/nmoehrle/mvs-texturing
                    G2LTex
                        https://github.com/fdp0525/G2LTex
                        as depth frames 
                        under ubuntu 
                    the one from gumhold 
                    open3d 
                        http://www.open3d.org/docs/0.10.0/index.html

            explore 
                https://arxiv.org/list/cs.GR/recent
                dense reconstruction
                depth images 
                high quality meshes 

            approaches:
                https://arxiv.org/list/cs.GR/recent
                [Bernardini99] Ball-Pivoting 
                [2001] power crust
                    using the hull convex hull code by Ken Clarkson
                    The power crust, 6th ACM Symposium on Solid Modeling, 2001
                    The power crust, unions of balls, and the medial axis transform, 2001
                [2006] Poisson
                    https://github.com/mkazhdan/PoissonRecon
                    http://sites.fas.harvard.edu/~cs277/papers/poissonrecon.pdf
                    M. Kazhdan, M. Bolitho, H. Hoppe, Poisson surface
                    reconstruction, Symposium on Geometry Processing
                    2006, 61-70
                    color values from the input samples can be obtained by calling:
                    https://github.com/mkazhdan/PoissonRecon
                    http://www.cs.jhu.edu/~misha/MyPapers/SGP06.pdf
                    https://github.com/mkazhdan/PoissonRecon#EXECUTABLES
                    http://www.cs.jhu.edu/~misha/Code/
                    http://www.cs.jhu.edu/~misha/Code/PoissonMesh/TextureStitcher/
                [2007] out-of-core poisson 
                [2007] Efficient RANSAC for Point-Cloud Shape Detection
                    https://cg.cs.uni-bonn.de/en/publications/paper-details/schnabel-2007-efficient/
                [2012] Fast Range Image Segmentation and Smoothing using Approximate Surface Reconstruction and Region Growing
                    https://www.ais.uni-bonn.de/papers/IAS_2012_Holz.pdf    
                [2013] SSDPoisson 
                [KÃ¶nig13] by gumhold https://tud.qucosa.de/api/qucosa%3A27391/attachment/ATT-0/ 
                [2014] State of the Art in Surface Reconstruction from Point Clouds
                    https://matthewberger.github.io/papers/reconstar.pdf
                [2015] Structured Indoor Modeling
                    https://openaccess.thecvf.com/content_iccv_2015/papers/Ikehata_Structured_Indoor_Modeling_ICCV_2015_paper.pdf
                [2017] Field-Aligned Online Surface Reconstruction
                    https://dl.acm.org/doi/pdf/10.1145/3072959.3073635
                    OnlineSurfaceReconstruction
                    https://github.com/NSchertler/OnlineSurfaceReconstruction
                [2017/2019] PolyFit: Polygonal Surface Reconstruction from Point Clouds
                    https://3d.bk.tudelft.nl/liangliang/publications/2017/polyfit/PolyFit-ICCV2017.pdf
                    seeking for an appropriate
                        combination of them to obtain a manifold polygonal
                        surface model without boundary
                    usage 
                        // make sure point cloud has normals!, in ply format is better 
                        use mapple to extract planes (ransac) -> bvg format 
                        import yo polyfit -> 
                    * Since Aug.5, 2019, PolyFit is officially part of CGAL.
                    a good commercial example .... 
                    binary labeling problem
                    Our method is based on  a hypothesizing and selection strategy
                    We first generate a  reasonably large set of face candidates by intersecting the  extracted planar primitives
                    Then an optimal subset of the  candidate faces is selected through optimization
                    enforce the final polygonal  surface model to be manifold and watertight
                    generate lightweight polygonal surface models  of arbitrary piecewise planar objects
                    recovering sharp features and is robust to  noise, outliers, and missing data
                    it has been extensively researched in  the past few decades
                    man-made objects such as buildings)
                    Second, it  should be able to recover sharp features of the objects.
                    C:\Users\yzhon\Downloads\PolyFit_data\PolyFit_data
                    as bvg (Binary Vertex Group) format.
                    bvg (Binary Vertex Group) format.
                    ASCII format vg also works but slow.
                    PolyFit assumes that the model is closed and all necessary planes are provided.
                    Gurobi, SCIP, GLPK, and lp_solve, are provided (with source code) in PolyFit
                    The GLPK and lp_solve solvers only manage to solve small problems. 
                    may not guarantee to succeed
                    incorporates a progress logger in the user interface
                [2017] A Survey of Surface Reconstruction from Point Clouds
                    https://hal.inria.fr/hal-01348404v2/document
                [2019] Dense 3D Point Cloud Reconstruction Using a Deep Pyramid Network
                    https://github.com/val-iisc/densepcr
                
                [2018] InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes Dataset

                [2019] The Replica Dataset: A Digital Replica of Indoor Spaces
                    https://arxiv.org/pdf/1906.05797.pdf
                    https://github.com/facebookresearch/Replica-Dataset
                    from facebook research 

                [sig2020] [0.2] Automatic 3D Reconstruction of Structured Indoor Environments tutorial notes 
                    https://dl.acm.org/doi/pdf/10.1145/3388769.3407469
                    need to cope with noisy  and partial captured data
                    many open research problems remain,
                    bridging complementary views coming from computer graphics  and computer vision
                    https://dl.acm.org/doi/pdf/10.1145/3388769.3407469
                    Automatic 3D Reconstruction of  Structured Indoor Environments
                    we provide an up-to-date integrative view of the field
                    main components of a  structured reconstruction pipeline
                    We finally  point out relevant research issues and analyze research trends
                    SIGGRAPH2020 Courses




                toread:
                    Mls
                    APSS
                    RIMLS
                    Voronoi Graph ï¼‹ PCA
                    Wavelet
                    https://lgg.epfl.ch/publications/2014/reconstar/paper.pdf
                    Nico papers: 
                        https://tud.qucosa.de/api/qucosa%3A32056/attachment/ATT-0/?L=1
                    https://arxiv.org/pdf/1703.04079.pdf
                    https://3d.bk.tudelft.nl/liangliang/publications/2009/BATR_2009.pdf
                    https://www.mdpi.com/2220-9964/9/5/330/pdf
                    RandLANet: Efficient Semantic Segmentation of Large-Scale PointClouds
                    Pytorch: Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction
                    https://tud.qucosa.de/search/?no_cache=1&L=1&tx_dpf_frontendsearch%5Baction%5D=search&tx_dpf_frontendsearch%5Bcontroller%5D=SearchFE
                    G2LTex
                        http://graphvision.whu.edu.cn/papers/fuyangping-Texture%20Mapping%20for%203D%20Reconstruction%20with%20RGB-D%20Sensor.pdf
                    https://github.com/NVlabs/intrinsic3d
                    https://github.com/AOT-AG/DicomToMesh
                    https://github.com/zishun/HRBFQI
                    https://github.com/VVingerfly/surfRecon

            stru: (pointing upwards)
                Voronoi based methods 
                    Crust
                    Power Crust 
                    cocone
                    umbrella filter
                        project point neighborhood into 2D tangent space
                        compute local 2D Delaunay triangulation   
                    [KÃ¶nig13]            
                Indicator Function Based Reconstruction
                    Poisson
                    Screened Poisson
                        M. Kazhdan, H. Hoppe. Screened Poisson surface
                            reconstruction, ACM Trans. Graphics, 32(3), 2013
                        SSD: Smooth Signed Distance Surface Reconstruction

        topic: SfM 
            preview 
                benchmark
                    rectified images from DTU benchmark
                https://zhuanlan.zhihu.com/p/131590433
                SfM 
                    https://zhuanlan.zhihu.com/p/78533248
                    Structure From Motion(SFM) æ˜¯ä»ä¸€ç³»åˆ—åŒ…å«è§†è§‰è¿åŠ¨ä¿¡æ¯çš„å¤šå¹…äºŒç»´å›¾åƒåºåˆ—ä¸­ä¼°è®¡ä¸‰ç»´ç»“æ„çš„æŠ€æœ¯
                    SFMå’Œç«‹ä½“è§†è§‰çš„åŒºåˆ«
                shape from shading: SfS
                PointMVSNet is a deep point-based deep framework for multi-view stereo (MVS).
                    PointMVSNet generates per-view depth map.
            hands-on 
                soft
                    https://github.com/alicevision/meshroom
                libs 
                    https://github.com/alicevision/meshroom
                    https://openmvg.readthedocs.io/en/latest/
            approaches: 

            stru: 

        topic: SfS
            ...

        topic: Structure from [depth videos/ videos] 
            prob:
                depth video capturing? 
                depth video recon? 
            hands-on 

            approaches:
                [2017] bundlefusion
                    most easy and powerful one 
                    recon from depth video 
                    it is not on point clouds actually 
            
            stru: 
                ...
        
        topic: polyfit, from point cloud to meshes constructive way 
            preview: 
                provided by cgal 
            keyword:
                fit point cloud to primitives 
            approaches: 

            stru: 

    --- 
    meshes -> meshes 
        
        topic: mesh reduction/ geometry processing 
            preview 
            hands-on 
                RGL epfl publications: 
                    http://rgl.epfl.ch/publications

            approaches
                [2015]  Instant Field-Aligned Meshes
                    https://igl.ethz.ch/projects/instant-meshes/instant-meshes-SA-2015-jakob-et-al.pdf
            stru

    --- 
    meshes -> textured meshes  
        
        topic: texture reconstruction
            preview: 
                åŸºæœ¬çŸ¥è¯† 
                    https://zhuanlan.zhihu.com/p/144332091  
                    è®©åœºæ™¯æ‹¥æœ‰ä¸°å¯Œçš„é¢œè‰²ä¿¡æ¯
                    çº¹ç†è´´å›¾ç²¾åº¦å¤§å°æ‰€å¸¦æ¥çš„é—®é¢˜
                    æˆ‘ä»¬å¯ä»¥å°†ä¸‰ç»´ç‰©ä½“ä¸Šçš„ä»»æ„ä¸€ä¸ªç‚¹éƒ½æ˜ å°„åˆ°ä¸€ä¸ª2ç»´å¹³é¢ä¹‹ä¸Š
                    æ¯æ¬¡åˆ©ç”¨å…‰ç…§æ¨¡å‹è¿›è¡Œè®¡ç®—çš„æ—¶å€™æ ¹æ®æ˜ å°„å…³ç³»å°±èƒ½æŸ¥åˆ°è¿™ä¸ªç‚¹çš„æ¼«åå°„ç³»æ•°æ˜¯å¤šå°‘
                    æœ‰äº†æ˜ å°„å…³ç³»ï¼Œå¯¹æ¸²æŸ“ç»“æœä¼šæœ‰ä¸€ä¸ªéå¸¸å¤§æå‡ï¼Œå› ä¸ºå¾ˆå¤šfancyçš„æ•ˆæœéƒ½å¯ä»¥é€šè¿‡textureçš„è®¾è®¡å¾—åˆ°
                    è¿™å°±è¦ä»çº¹ç†åæ ‡ï¼ˆUVï¼‰è¯´èµ·äº†
                    è‡³äºä¸€ä¸ªé¡¶ç‚¹æ‰€å¯¹åº”åœ¨çº¹ç†ç©ºé—´çš„åæ ‡æ˜¯æ€ä¹ˆå¾—åˆ°çš„ï¼Œè¿™å°±å¹¶ä¸æ˜¯ç¨‹åºå‘˜ä»¬å…³å¿ƒçš„äº†
                    å› æ­¤åªéœ€è¦åœ¨ä¸‰ç»´world spaceä¸­æ¯ä¸ªé¡¶ç‚¹çš„ä¿¡æ¯ä¹‹ä¸­å­˜å‚¨ä¸‹è¯¥é¡¶ç‚¹åœ¨texture spaceçš„(u,v)åæ ‡ä¿¡æ¯
                    æœ‰ä¸€ç§ç‰¹æ®Šçš„çº¹ç†ç§°ä¸ºtileï¼Œè¿™ç§çº¹ç†çš„ç‰¹å¾æ˜¯é‡å¤æ‹¼æ¥ä¹‹åä¸Šä¸‹å·¦å³éƒ½æ˜¯è¿ç»­çš„ï¼Œå› æ­¤è¿™ç§çº¹ç†å¯ä»¥å¤åˆ¶å¾ˆå¤šå¼ è´´åœ¨å¢™é¢æˆ–åœ°æ¿ä¸Šã€‚
                    é‡å¤åˆ©ç”¨è¿™ç§è´´å›¾
                    https://pic3.zhimg.com/80/v2-7ac2e368b1b3287e5ebb4fef55d5dc82_1440w.jpg
                    è€ƒè™‘å¦‚æœçº¹ç†ç²¾åº¦ç‰¹åˆ«å°(reslutionä½)æˆ–è€…çº¹ç†ç²¾åº¦ç‰¹åˆ«å¤§(reslutionå¤§)ä¼šåˆ†åˆ«å¼•èµ·ä»€ä¹ˆé—®é¢˜å‘¢
                    æ›´åŠ ç²¾ç»†çš„é€‰æ‹©åç»“æœå°±ä¼šæ˜æ˜¾å¥½å¾ˆå¤š:
                    éš¾çš„æ˜¯ååºçš„çº¹ç†è¿‡å¤§è¿‡å°å¼•å‘çš„é—®é¢˜ï¼Œå¯èƒ½ç›¸å¯¹è€Œè¨€æœ‰äº›æŠ½è±¡ï¼Œéœ€è¦è‡ªå·±ä»”ç»†æ€è€ƒæ€è€ƒ
                    åŒ…æ‹¬è§£å†³é—®é¢˜çš„ä¸€äº›æ–¹æ³•Mipmapsï¼Œå„å‘å¼‚æ€§è¿‡æ»¤ä»€ä¹ˆçš„
                    GAMES101-ç°ä»£è®¡ç®—æœºå›¾å½¢å­¦å…¥é—¨-é—«ä»¤çª
                    https://pic2.zhimg.com/80/v2-cbe5ed359de8bbf3f59825e74c38fefd_1440w.jpg
                    http://www.reynantemartinez.com/how-to-generate-texture-maps-from-a-single-image.html
                    è¦åˆ›å»ºçœŸå®ä¸–ç•Œä¸­ç½•è§çš„æè´¨ï¼Œçš®è‚¤å°±ä¸å¥½æ‰¾äº†ã€‚
                    å¯ä»¥å°†ä¸‰ç»´ Mesh(ç½‘æ ¼)ä»¥æŒ‡å®šæ–¹å¼ä¸é¢œè‰²ã€è´´å›¾ç­‰ç»„åˆï¼Œå®Œæˆå¤æ‚çš„è®¡ç®—è¾“å‡ºï¼ˆæ¸²æŸ“å™¨å¯è¯»å–çš„ç‚¹å’Œé¢œè‰²çš„å¯¹åº”å…³ç³»ï¼‰
                    ä¸ºä»€ä¹ˆ Shaders è¿è¡Œç‰¹åˆ«å¿«ï¼Ÿå› ä¸ºå®ƒä»¬å¸¸å¸¸è¿è¡Œåœ¨ä¸“é—¨ä¸ºå¹¶è¡Œå¤„ç†ï¼ˆparallel processingï¼‰è€Œè®¾è®¡çš„ GPU ä¸Šé¢ã€‚
                    åŒ…å«ä¸€äº›é’ˆå¯¹å‘é‡å’ŒçŸ©é˜µæ“ä½œçš„æœ‰ç”¨ç‰¹æ€§ã€‚
                    å†…å­˜çš„å¢é•¿é€Ÿåº¦è¿œè¿œè·Ÿä¸ä¸Šçº¹ç†åˆ†è¾¨ç‡çš„å¢é•¿é€Ÿåº¦ã€‚ç‰¹åˆ«æ˜¯å¯¹äºç§»åŠ¨å¹³å°ï¼Œå¦‚æœè¦åšé«˜å¤æ‚åº¦çš„åœ°å½¢ï¼Œå¹¶ä¸”åœ°å½¢ä¸Šæ¯”å¦‚ä¼šæœ‰è½¦å°è¿™äº›å„ç§è´´èŠ±ï¼Œé‚£å¯¹äºè´´å›¾çš„ä½¿ç”¨æ˜¯éå¸¸é¢‘ç¹çš„
                    è´´å›¾tileæˆå¾ˆå¤šå°å—ï¼Œç„¶åä¸ºæ¯å—æŒ‡å®šä¸€ä¸ªIDå·ï¼Œæœ€åpackåˆ°ä¸€å¼ å¤§çš„è´´å›¾ä¸­
                    åŠ¨æ€downsample
                    Chen_Ka_AdaptiveVirtualTexture
                    Texture antialiasing (MIPMAP)
                    Signed Distance Function
                    å¯ä»¥ç”¨æ¯ä¸ªpatchçš„model space UV
                    it may not support all flavors of obj. 
                    share the other problematic model you mention
                    https://geometrycollective.github.io/boundary-first-flattening/
                    https://github.com/GeometryCollective/paper-template
                    procedural rendering 
                    http://www.alecjacobson.com/weblog/?tag=libigl
                    å·²é€šè¿‡æŸç§æ–¹å¼ç¼–è¾‘æˆ–ä¿®æ”¹æ›²é¢
                    æ— éæ˜¯ä¸ºäº†å®Œæˆä¸€ä¸ªå…±åŒç›®æ ‡ï¼šç”¨è®¡ç®—æœºè¡¨ç°çœŸå®å¯ä¿¡çš„ Shadingã€‚
                        Shading æ˜¯çœŸå®ä¸–ç•Œä¸­çš„å…‰å½±æ•ˆæœï¼Œå®ƒæ˜¯ç”±ç‰©ä½“è¡¨é¢æè´¨ã€ç¯å…‰ã€è§‚å¯Ÿè€…çš„è§†è§’ç­‰å¤šç§å› ç´ å…±åŒå†³å®šçš„
                        Diffuse Map æ¼«åå°„ï¼šæ¨¡æ‹Ÿä¸€ä¸ªå‘å…‰ç‰©å¯¹ç‰©ä½“çš„æ–¹å‘æ€§å½±å“(Directional Impact)ã€‚å®ƒæ˜¯å…‰ç…§æ¨¡å‹ä¸­æœ€æ˜¾è‘—çš„ç»„æˆéƒ¨åˆ†
                        Normal/Bump Map æ³•çº¿ï¼šå†³å®šç‰©ä½“å½¢çŠ¶çš„å‚ç›´äºå®ƒçš„æ³•çº¿å‘é‡ï¼Œæä¾›æœ‰å…³ç‰©ä½“è¡¨é¢æ·±åº¦çš„ç»†èŠ‚ã€‚æ¯ä¸€ç§é¢œè‰²ä»£è¡¨äº†ä¸åŒçš„è½´å‘
                        Displacement Map ä½ç§»ï¼šä½¿ç”¨é«˜åº¦å›¾å°†ç»è¿‡çº¹ç†åŒ–çš„è¡¨é¢çš„å®é™…å‡ ä½•ç‚¹ä½
                        Gloss/Roughness Map å…‰æ³½  
                
                å¤„ç†èµ°æ ·å¤±çœŸ
                    æœ€è¿‘çš„é‚£ä¸ªåƒç´ ç‚¹ï¼Œå¾€å¾€ä¼šé€ æˆä¸¥é‡çš„èµ°æ ·ã€‚
                    åŒçº¿æ€§æ’å€¼çš„æ–¹æ³•ç¼“è§£è¿™ç§èµ°æ ·ç°è±¡
                    èƒ½å¤Ÿå¾ˆå¥½çš„ç¼“è§£èµ°æ ·å¤±çœŸç°è±¡ï¼Œå¹¶ä¸”è®¡ç®—é€Ÿåº¦è¾ƒé«˜ã€‚
                    (tips:è¿˜æœ‰ä¸€ç§æ’å€¼æ–¹æ³•å«åšåŒä¸‰æ¬¡æ’å€¼(Bicubic),æ˜¯åˆ©ç”¨ä¸‰æ¬¡æ–¹ç¨‹æ¥è¿›è¡Œä¸¤æ¬¡æ’å€¼ï¼Œæ•ˆæœå¯èƒ½æ›´å¥½ï¼Œä½†æ˜¯è®¡ç®—é€Ÿåº¦å¾ˆä½ä¸åœ¨è¿™é‡Œå…·ä½“è®¨è®ºäº†)
                    è¿‘å¤„é”¯é½¿ï¼è¿œå¤„æ‘©å°”çº¹ï¼éå¸¸ä¸¥é‡çš„èµ°æ ·ç°è±¡ï¼Œä¸ºä»€ä¹ˆä¼šå¯¼è‡´è¿™æ ·çš„ä¸€ä¸ªç°è±¡å‘¢ï¼Ÿ
                    è¿œå¤„åœ†åœˆé‡Œçš„footprintå¿…ç„¶æ¯”è¿‘å¤„çš„è¦å¤§ï¼Œå› æ­¤å¿…é¡»è¦å‡†å¤‡ä¸åŒlevelçš„åŒºåŸŸæŸ¥è¯¢æ‰å¯ä»¥ï¼Œè€Œè¿™æ­£æ˜¯Mipmapã€‚
                    å¾ˆé—æ†¾ï¼Œåœ¨æœ¬æ–‡çš„é‚£ä¸ªåœ°æ¿çš„ä¾‹å­ä¹‹ä¸­ï¼Œè´¹äº†è¿™ä¹ˆå¤§åŠ›æ°”ä¾ç„¶ä¸èƒ½å®Œç¾è§£å†³ï¼Œå¦‚ä¸‹å›¾ç»“æœ:
                    è¿œå¤„çš„åœ°æ¿äº§ç”Ÿä¸€ç§è¿‡æ›çš„ç°è±¡ï¼Œå®Œå…¨ç³Šåœ¨äº†ä¸€èµ·ã€‚è¯¥å¦‚ä½•è§£å†³è¿™ä¸ªæœ€åçš„é—®é¢˜å‘¢â€”â€”å„å‘å¼‚æ€§è¿‡æ»¤ã€‚
                    æœ‰çš„æ‰€éœ€è¦çš„æ˜¯ä»…ä»…æ˜¯æ°´å¹³æ–¹å‘çš„é«˜levelï¼Œæœ‰çš„éœ€è¦çš„ä»…ä»…æ˜¯ç«–ç›´æ–¹å‘ä¸Šçš„é«˜levelï¼Œå› æ­¤è¿™ä¹Ÿå°±å¯å‘äº†å„å‘å¼‚æ€§çš„è¿‡æ»¤
                    æœ‰çš„æ‰€éœ€è¦çš„æ˜¯ä»…ä»…æ˜¯æ°´å¹³æ–¹å‘çš„é«˜level
                    https://pic2.zhimg.com/80/v2-ff995b8eddf01433063df0d7eca9f175_1440w.jpg
                    ä¸ªäººæ„Ÿè§‰ï¼Œåº”è¯¥æ˜¯è¦ç®—å‡ºæ°´å¹³æ–¹å‘çš„level D0ï¼Œå†ç®—ä¸€ä¸ªç«–ç›´æ–¹å‘çš„level D1ï¼Œ
                        ç„¶åç®—æ ¹æ®è¿™ä¸¤ä¸ªlevelå»å„é¡¹å¼‚æ€§è¿‡æ»¤çš„textureé‡Œé¢æ‰¾ä¸€å¼ æœ€åˆé€‚çš„
            
                Virtual Texture Mapping
                    è¿™é‡Œä½œè€…ä¹Ÿæå‡ºäº†æ–°çš„mipmapå¯¹åº”çš„æ–¹æ¡ˆï¼Œå°±æ˜¯ä¸€æ¬¡æ¯”åŸæ¥çš„mipmapå¢åŠ ä¸€ä¸ªçº§åˆ«ã€‚
                    A virtual texture2 is a mip?mapped texture used as cache to allow a much higher  resolution texture to be emulated for real?time rendering, while only partly residing in  texture memory
                    LOD selection
                    float precision, disk streaming, UV borders,  mip?map generation
                    large rich environments with many details
                    CrysisTM shows the need for texture streaming:  
                    virtual texture
                    https://developer.amd.com/wordpress/media/2013/01/Chapter02-Mittring-Advanced_Virtual_Texture_Topics.pdf
                
                Procedural Texture 
                    ç¨‹åºåŒ–ç”Ÿæˆçš„çº¹ç† 
                
                ä½å›¾å›¾åƒ
                    ç”¨æ•°ç ç›¸æœºæ‹æ‘„çš„ç…§ç‰‡ã€æ‰«æä»ªæ‰«æçš„å›¾ç‰‡ä»¥åŠè®¡ç®—æœºæˆªå±å›¾ç­‰éƒ½å±äºä½å›¾ã€‚
                
                the .gltf file format 
                    may reference external binary and texture resources
                    Graphics Language Transmission Format
                    has been adopted by other 3D graphics application vendors.
                    Vertices are stored in a counter-clockwise order by default
                    https://en.wikipedia.org/wiki/Wavefront_.obj_file#Texture_maps
                    standard file format for three-dimensional scenes and models.
                
                æœ‰åºç‚¹äº‘å’Œæ— åºç‚¹äº‘
                    ä¸€èˆ¬ä½¿ç”¨tofæˆ–è€…ç»“æ„å…‰åŸç†çš„æ·±åº¦ç›¸æœºè·å–çš„ç‚¹äº‘æ˜¯æœ‰åºç‚¹äº‘ï¼Œè€Œæ— åºç‚¹äº‘ä¸€èˆ¬æ˜¯æ¿€å…‰é›·è¾¾å…¶ä»–è®¾å¤‡è·å–çš„ï¼Œæ— åºç‚¹å°±ç”¨ä¸‹é¢çš„å›¾ç†è§£å§ã€‚

            prob: uv texture mapping in game and film making. industry standard? 
                summ: uv å±•å¼€ï¼Œç„¶åè‰ºæœ¯å®¶æ‰‹åŠ¨ç»‘ä¸Šå»çš„ã€‚ä¹Ÿæœ‰ç›´æ¥å¾€æ¨¡å‹ä¸Šç”»çš„æŠ€æœ¯æ¯”å¦‚PTex
                å»ºæ¨¡çš„æ—¶å€™çº¹ç†è´´å›¾æ˜¯æ€ä¹ˆç”Ÿæˆçš„: https://www.zhihu.com/question/49399106
                    i use painter to texture my models and uv mapping will waist many of my time . 
                        i hope substance support ptex soon 
                    https://www.unwrap3d.com/u3d/tutorial_uv_mapping_repaint_mesh.aspx
                    https://zhxx1987.github.io/
                    https://v.youku.com/v_show/id_XNDM3ODU0MzQxNg==.html?spm=a2h0j.11185381.listitem_page1.5!8~A
                    mental ray 3.10.
                prob: å¤šä¸ªæè´¨å¦‚ä½•æ¸²æŸ“
                fï¼šuvå±•å¼€, ç”¨blender, mayaå¡«å……
                
            hands-on: 
                soft:
                    ZBrush 
                        is a digital sculpting tool that combines 3D/2.5D modeling, texturing and painting. 
                        It uses a proprietary "pixol" technology which stores lighting, color, material, orientation, and depth information for the points making up all objects on the screen
                        Our flagship product and the industry standard for 3D sculpting
                        since we only supplied 3 colors, not the huge color palette we're seeing right now.
                        This is all the result of something called fragment interpolation in the fragment shader. 
                        results in a lot more fragments than vertices originally specified. 
                        The rasterizer then determines the positions of each of those fragments based on where they reside on the triangle shape.         
                    Maya texture mapping 
                        è“è‰²æ„å‘³ç€å…‰ç…§å›¾ç²¾åº¦è¿‡ä½
                        åœ¨ UE4 ä¸­æ„å»ºå…‰ç…§å›¾æ—¶å¯èƒ½å‡ºç°ç©¿å¸®ã€‚çº¢è‰²æ„å‘³ç€å…‰ç…§å›¾ç²¾åº¦è¿‡é«˜
                        åº”ç”¨åœ¨ç°æœ‰å‡ ä½•ä½“ä¸Šæœ‰æµªè´¹ä¹‹å«Œã€‚
                        å›¾åƒä¸­ï¼Œé¥¼å¹²ç›’çš„å‰ã€åã€ä¸Šã€ä¸‹å’Œä¸¤ä¾§éƒ½åŒ…å«ç”¨ Adobe? Photoshop?ï¼ˆ.PSD æ ¼å¼ï¼‰åˆ›å»ºçš„ 2D è‰ºæœ¯å›¾
                        https://download.autodesk.com/us/maya/maya_2014_gettingstarted_chs/images/GUID-4408F054-A27F-4792-BC3A-119D5A4E3655-low.png
                        çº¹ç†åæ ‡å¥½è®¡ç®—ï¼Œè´´å›¾ä¹Ÿå°±æ˜¯ä¸€å¼ ç®€å•çš„çŸ©å½¢å›¾ç‰‡
                        https://www.zhihu.com/question/49399106
                    Blender texturing
                        UV mapping is a technique used to "wrap" a 2D image texture onto a 3D mesh
                            "U" and "V" are the names of the axes of a plane,
                            UV/Image Editor. 
                        https://en.wikibooks.org/wiki/Blender_3D:_Noob_to_Pro/UV_Map_Basics
                            equator
                            This tells the UV unwrapper to cut the mesh along these edges.
                            create a window for the UV mapping
                            Save the following image (click to view in full high resolution (4,096 Ã— 2,048 pixels)):
                            Then with the grab, rotate and scale tools
                            adjust the UV islands
                            Admire your new creation
                            To make the texture visible in renderings, you also need to add the texture to the sphere as a new material.
                            Select the globe texture from the dropdown menu.
                            I've changed the lighting and the camera position to make the image more interesting
                            I also added a star background
                            spherical mapping.
                            blue marble
                            most detailed true-color image of the entire Earth to date
                            seamless, true-color mosaic of every square kilometer (.386 square mile) of our planet
                            https://earthobservatory.nasa.gov/features/BlueMarble/BlueMarble_2002.php
                            you should see a very different UV map, as shown below. Note that only the 'Unwrap' option will use the seams we just made, all of the other options completely ignore it.
                            UVs fit more evenly over the texture
                            Now rerender your model, and you will see that there are no seams!
                            Noob to Pro
                            https://en.wikibooks.org/wiki/Blender_3D:_Noob_to_Pro 

                        https://www.youtube.com/watch?v=bP_1XfpEy80  
                    geometryhub
                        http://geometryhub.net/notes/uvunfold
                        æœ‰äº›åº”ç”¨åœºæ™¯ä¸éœ€è¦ç¨ å¯†çš„ç½‘æ ¼ï¼Œéœ€è¦å¯¹ç½‘æ ¼è¿›è¡Œç®€åŒ–
                        ç½‘æ ¼ç®€åŒ–ä¸ä¼šå½±å“å›¾ç‰‡çš„åˆ†è¾¨ç‡ï¼Œä¸‹å·¦å›¾ä¸ä¸Šé¢çš„ç¨ å¯†ç½‘æ ¼æ¯”è¾ƒï¼Œè§†è§‰ä¸Šçš„è‰²å½©æ˜¯å·®ä¸å¤šçš„ã€‚
                        ç”¨åŸå§‹å›¾ç‰‡åšçº¹ç†è´´å›¾ï¼Œåœ¨ä¸åŒå›¾ç‰‡æ¥ç¼å¤„ï¼Œæœ‰æ˜æ˜¾çš„è‰²å·®ç—•è¿¹ã€‚çº¹ç†è‰²å½©èåˆå¯ä»¥æå‡çº¹ç†è´´å›¾æ•´ä½“çš„è‰²å½©èåˆåº¦
                        å¦‚æœèƒ½æŠŠå®ƒä¸å‚æ•°å¹³é¢å»ºç«‹ä¸€ä¸€æ˜ å°„ï¼Œé‚£ä¹ˆå®ƒä¹Ÿå°±è¢«å‚æ•°åŒ–äº†ï¼Œè¿™ä¸ªæ˜ å°„å°±æ˜¯UVå±•å¼€
                        åªæœ‰åœ†ç›˜æ‹“æ‰‘ç»“æ„çš„ç½‘æ ¼æ‰èƒ½å±•å¼€åˆ°å¹³é¢ä¸Š
                        ä¸€ç§æ˜¯æ›²é¢æœ¬èº«çš„å‡ ä½•æ‰€å†³å®šçš„ï¼Œæ¯”å¦‚çƒé¢å±•å¼€åˆ°å¹³é¢ï¼Œä¸€å®šä¼šäº§ç”Ÿæ‰­æ›²ã€‚æƒ³è¦å‡å°‘å±•å¼€çš„æ‰­æ›²ç¨‹åº¦ï¼Œå¯ä»¥åœ¨æ‰­æ›²ç¨‹åº¦å¤§çš„åœ°æ–¹å¢åŠ æ›²é¢å‰²çº¿ã€‚å¦ä¸€ç§æ˜¯å±•å¼€ç®—æ³•ä¸­çš„çº¦æŸäº§ç”Ÿçš„æ‰­æ›²ï¼Œæ¯”å¦‚å›ºå®šè¾¹ç•Œçš„UVå±•å¼€
                        ä¸€ç§ç›´è§‚çš„è§‚å¯Ÿå±•å¼€æ‰­æ›²ç¨‹åº¦çš„æ–¹å¼æ˜¯ï¼ŒæŠŠä¸€å¼ æ£‹ç›˜æ ¼å›¾ç‰‡è´´åˆ°ç½‘æ ¼ä¸Šï¼Œæ£‹ç›˜æ ¼è¶Šå‡åŒ€ï¼ŒUVå±•å¼€æ‰­æ›²è¶Šå°ã€‚
                        http://geometryhub.net/images/texturecoord.jpg
                        é¡¶ç‚¹åæ ‡ä¸çº¹ç†åæ ‡å…¶å®æ²¡æœ‰ç›´æ¥è”ç³»
                        ä»–ä»¬æ˜¯ç”¨è¿‡ä¸‰è§’é¢ç‰‡é—´æ¥è”ç³»èµ·æ¥çš„
                        é¡¶ç‚¹å¹¶æ²¡æœ‰çº¹ç†åæ ‡çš„æ¦‚å¿µï¼Œåªæœ‰ä¸‰è§’å½¢æœ‰çº¹ç†åæ ‡çš„æ¦‚å¿µ
                        å¦‚æœæ²¡æœ‰å‰²ç¼äº§ç”Ÿï¼Œé‚£ä¹ˆæ¯ä¸ªé¡¶ç‚¹åœ¨å…¶ç›¸é‚»ä¸‰è§’å½¢å†…çš„çº¹ç†åæ ‡éƒ½æ˜¯ä¸€æ ·çš„
                        å•è¿é€šåœ†ç›˜æ‹“æ‰‘çš„UVå±•å¼€ï¼šå¦‚å›¾1æƒ…å†µæ‰€ç¤ºã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œé¡¶ç‚¹å’Œçº¹ç†åæ ‡æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œä¸€ä¸ªé¡¶ç‚¹å¯ä»¥å­˜ä¸€ä¸ªçº¹ç†åæ ‡ã€‚ä¸€èˆ¬è¿™ç±»çš„UVå±•å¼€ï¼Œéƒ½æ˜¯ä½¿ç”¨çš„é¡¶ç‚¹çº¹ç†åæ ‡çš„æ¦‚å¿µã€‚
                        UVå±•å¼€çš„åº”ç”¨é‡Œï¼Œç»å¸¸éœ€è¦åˆ›å»ºä¸€äº›ç½‘æ ¼å‰²ç¼
                        å¥½çš„å‰²ç¼ï¼Œä¸€èˆ¬æœ‰è¿™äº›æ€§è´¨ï¼š
                        é•¿åº¦å¾ˆçŸ­  å‰²çº¿å…‰æ»‘  æ²¿ç€ç‰¹å¾è¾¹  åˆ†å¸ƒåœ¨è§†è§‰ä¸æ˜æ˜¾çš„åœ°æ–¹  åœ¨å…¨è‡ªåŠ¨UVå±•å¼€åº”ç”¨é‡Œï¼Œå‰²ç¼é¦–å…ˆè¦èƒ½æŠŠç½‘æ ¼å‰²æˆä¸€ç‰‡ä¸€ç‰‡çš„åœ†ç›˜ç»“æ„
                        ç½‘æ ¼UVå±•å¼€åˆ°å¹³é¢åï¼ŒæŠŠç½‘æ ¼å¯¹åº”çš„è´´å›¾å¡«å……åˆ°UVåæ ‡åŸŸï¼Œå°±å¾—åˆ°äº†å³è¾¹çš„çº¹ç†å›¾ã€‚
                        å¡«å……
                        ç½‘æ ¼åœ¨æ¸²æŸ“çš„æ—¶å€™ï¼Œæ¯ä¸ªä¸‰è§’ç‰‡ç¦»æ•£åŒ–åï¼Œæ¯ä¸ªç¦»æ•£ç‚¹ä¼šæ ¹æ®UVåæ ‡å€¼å»çº¹ç†å›¾é‡Œæ‹¾å–é¢œè‰²ã€‚
                            æ‹¾å–çš„æ–¹æ³•ï¼Œå¯ä»¥æ˜¯UVåæ ‡å€¼æœ€è¿‘ç‚¹é¢œè‰²ï¼Œä¹Ÿå¯ä»¥æ ¹æ®UVåæ ‡å€¼çš„ç›¸é‚»å››ä¸ªåƒç´ åšåŒçº¿æ€§å·®å€¼ã€‚
                            http://geometryhub.net/notes/meshmapping
                        Så’ŒTé€šè¿‡åˆšæ€§å˜æ¢å°±å¯ä»¥æ³¨å†Œå¯¹é½ï¼Œå¦‚ä¸‹å·¦å›¾æ‰€ç¤ºã€‚å¦‚æœSå’ŒTæœ‰ç›¸åŒçš„ç½‘æ ¼è¿æ¥å…³ç³»ï¼Œé‚£ä¹ˆFå¯ä»¥æ˜¯ä¸€ä¸ªåˆšæ€§å˜æ¢
                        å¦‚æœSå’ŒTçš„ç½‘æ ¼è¿æ¥å…³ç³»æœ‰å·®å¼‚ï¼Œåˆ™Så’ŒTäº’ä¸ºå¯¹æ–¹çš„Remeshç½‘æ ¼ã€‚
                        ç¬¬äºŒç±»æƒ…å†µï¼ŒSå’ŒTæ˜¯åŒä¸€ç±»ç‰©ä½“ï¼ŒSå’ŒTå¯ä»¥é€šè¿‡è¿‘ä¼¼åˆšæ€§å˜æ¢æ³¨å†Œå¯¹é½ï¼Œæˆ–è€…å«éåˆšæ€§æ³¨å†Œï¼Œå¦‚ä¸‹ä¸­é—´å›¾æ‰€ç¤ºã€‚
                        ç¬¬ä¸‰ç±»æƒ…å†µï¼ŒSå’ŒTæ˜¯ä¸åŒç±»çš„ç‰©ä½“ï¼Œä½†æ˜¯å½¢çŠ¶ä¸Šç›¸ä¼¼ï¼Œæœ‰ç›¸åŒçš„æ‹“æ‰‘ç»“æ„ã€‚æ¯”å¦‚ä¸‹é¢å³å›¾æ‰€ç¤ºï¼ŒSå’ŒTéƒ½ä¸ºå››è‚¢åŠ¨ç‰©ï¼Œéƒ½æœ‰å°¾å·´ã€‚å®ƒä»¬ä¹‹é—´çš„æ˜ å°„æ¯”ç¬¬äºŒç±»è¦å¤æ‚ä¸€äº›ã€‚
                        åŒå°„ï¼šä¸¤ä¸ªç½‘æ ¼åœ¨æ˜ å°„åŒºåŸŸçš„æ˜ å°„ï¼ŒæœŸæœ›æ˜¯ä¸€ä¸ªåŒå°„ã€‚
                        æ‰­æ›²åº¦ï¼šæ˜ å°„æ‰­æ›²åº¦ç»å¸¸ç”¨äºåº¦é‡æ˜ å°„çš„å¥½åï¼Œä¼˜åŒ–èƒ½é‡é‡Œä¹Ÿå¸¸è§æ‰­æ›²åº¦çš„åº¦é‡ã€‚æœ€å¥½çš„æƒ…å†µæ˜¯ä¿è·çš„ï¼Œä¹Ÿå°±æ˜¯Sä¸Šä¸¤ç‚¹çš„è·ç¦»ï¼Œåœ¨æ˜ å°„åˆ°Tä¸Šåï¼Œä¹Ÿä¿æŒåŒæ ·çš„è·ç¦»
                        çº¹ç†è¿ç§»
                        å½©è‰²ç½‘æ ¼ä¸»è¦åˆ†ä¸¤ç±»ï¼Œä¸€ç±»æ˜¯å½©è‰²é¡¶ç‚¹ç½‘æ ¼ï¼Œä¸€ç±»æ˜¯å½©è‰²è´´å›¾ç½‘æ ¼ã€‚
                        ç½‘æ ¼é¡¶ç‚¹å¸¦æœ‰é¢œè‰²
                        ä¸‰è§’å½¢çš„é¢œè‰²ç”±ç½‘æ ¼é¡¶ç‚¹é¢œè‰²æ’å€¼å¾—åˆ°
                        ç½‘æ ¼çš„è‰²å½©åˆ†è¾¨ç‡ç­‰äºé¡¶ç‚¹åˆ†è¾¨ç‡
                        ç½‘æ ¼çš„ä¸‰è§’å½¢çš„é¢œè‰²å¯¹åº”äºå›¾åƒçš„ä¸€ä¸ªä¸‰è§’ç‰‡ã€‚ç½‘æ ¼çš„è‰²å½©åˆ†è¾¨ç‡ç­‰äºå›¾åƒçš„è‰²å½©åˆ†è¾¨ç‡
                        å½“ç½‘æ ¼é¡¶ç‚¹æ¯”è¾ƒå°‘çš„æ—¶å€™ï¼Œè‰²å½©ä¿¡æ¯ä¼šæŸå¤±å¾ˆå¤š
                        å½©è‰²è´´å›¾ç½‘æ ¼çš„è‰²å½©åˆ†è¾¨ç‡å–å†³äºçº¹ç†è´´å›¾çš„åˆ†è¾¨ç‡ï¼Œä¸ç½‘æ ¼é¡¶ç‚¹åˆ†è¾¨ç‡æ— å…³ï¼Œå¦‚å›¾3æ‰€ç¤ºï¼ŒåŒæ ·çš„ç½‘æ ¼ï¼Œçº¹ç†è´´å›¾æ–¹å¼å¯ä»¥å­˜å‚¨é«˜äºç½‘æ ¼åˆ†è¾¨ç‡çš„è‰²å½©ä¿¡æ¯ã€‚
                        çº¹ç†è´´å›¾æ–¹å¼å¯ä»¥å­˜å‚¨é«˜äºç½‘æ ¼åˆ†è¾¨ç‡çš„è‰²å½©ä¿¡æ¯ã€‚
                        å½©è‰²è´´å›¾ç½‘æ ¼çš„åˆ¶ä½œ
                        ç‚¹åƒå¯¹åº”çš„è®¡ç®—
                        ç½‘æ ¼å¯¹åº”çš„ç‚¹äº‘æœ‰ç‚¹åƒå¯¹åº”ï¼Œå¯ä»¥é€šè¿‡æŠ•å½±çš„æ–¹å¼æŠŠç‚¹äº‘çš„ç‚¹åƒå¯¹åº”æŠ•å½±åˆ°ç½‘æ ¼ä¸Šã€‚
                        ä¸åŒçš„é¢œè‰²ä»£è¡¨ä¸åŒçš„å›¾ç‰‡ã€‚å·¦è¾¹è´´å›¾æœ‰æ˜æ˜¾çš„å›¾åƒç¼éš™ç—•è¿¹ã€‚å³è¾¹è´´å›¾æ˜¯ä¼˜åŒ–åçš„ç»“æœï¼Œå›¾åƒç¼éš™è‰²å·®å‡å°å¾ˆå¤šã€‚    
                        ç¼éš™è‰²å·®
                        çº¹ç†è´´å›¾é¢œè‰²èåˆ
                        å³å›¾æ˜¯é¢œè‰²èåˆåçš„æ•ˆæœã€‚
                        æœ‰åºç‚¹äº‘å’Œæ— åºç‚¹äº‘
                            .e57 is ordered point cloud 
                        http://geometryhub.net/notes/pca
                        http://geometryhub.net/en/magic3d
                    realitycapture
                        texture from e57 files, texture atlasing possible 
                        limited input format for cracked version 
                        transfer to ordered point cloud? 
                            https://zhuanlan.zhihu.com/p/34816510
                    3DF Zephyr Lite
                        250 eu per month 
                        no crack version possible 
                    contextcapture
                        https://www.bentley.com/en/products/product-line/reality-modeling-software/contextcapture
                    Mudbox Autodesk 

                libs:
                    libigl 

            approaches:
                /// mixed 
                Kinect Fusion Microsoft Research 
                    as no built-in support for rendering a texture-mapped image.
                https://www.mdpi.com/2072-4292/12/23/3908/pdf
                https://en.wikipedia.org/wiki/Projective_texture_mapping
                    Texture matrix is introduced in section 2.11.2 "Matrices" of the OpenGL 2.0 specification.
                    Generating Texture Coordinates
                    the other from the projector point of view.
                    this is the eye-space vertex position if the considered projector would have been an observer.
                https://math.stackexchange.com/questions/681376/texture-mapping-from-a-camera-image-knowing-the-camera-pose
                    apply a texture (taken from a camera) on a 3D surface
                    sorry for my poor drawing skills
                    Here is a picture representing what I'm trying to achieve
                    If I take a point that is not in my camera range, the corresponding 2D point would not make any sense and so the texture mapping will be wrong
                    this point doesn't have an associated texture color
                    Nicely written question
                    I didn't expect that it would be so simple.
                    once you strip off the "1"
                
                [1998] Efficient View-Dependent Image-Based Rendering with Projective Texture-Mapping
                    https://www.pauldebevec.com/Research/VDTM/debevec_vdtm_egrw98.pdf
                    If multiple views are incorporated one  must determine which image is best to be mapped onto  which part of the surface
                    the angle between the  viewing direction during acquisition and the surface  normal may be considered
                    projective texture  mapping 
                    use the recovered geometry and the available real views  to generate novel views of the scene quickly and realistically.
                    with known locations and known imaging geom
                    in the same lighting conditions
                    Surfaces in the scene are not extremely specular
                    View-Dependent Texture Mapping (VDTM)
                    the rendering result with all the  holes filled. 
                    https://i.stack.imgur.com/SmVmD.png
                    UVProject
                    handle 360 textures
                    https://i.stack.imgur.com/o55e8.png
                    https://i.stack.imgur.com/6vCd6.gif
                [2000] Automated Texture Registration and Stitching for Real World Models
                    https://domino.mpi-inf.mpg.de/intranet/ag4/ag4publ.nsf/AuthorEditorIndividualView/10318a7f1923f921c12569dc003ca4ee/$FILE/pg2000.pdf
                    consumer quality digital cameras
                    Alternatively, the user can skip some steps  in the algorithm providing a rough alignment
                    a complete texture for an object
                    Imaging All Visible Surfaces
                    collect data for all visible surfaces
                    optimal set of required views respecting the viewing  angle
                    no further 3Dâ€“2D registration is needed
                    correspond to known points on the modelâ€™s  surface.
                    the camera transformation for the current view can be directly derived using standard camera calibration techniques
                    Kriegman et al. [7] use T-junctions  and other image features to constrain the modelâ€™s position and orientation
                    attach artificial landmarks to the objectâ€™s surface which are detected automatically in the images
                    these marks destroy  the texture and have to be removed afterwards
                    one may of course select corresponding pixels manually
                    A lot of previous algorithms try to find the camera  transformation by minimizing the error between the  contour found in the image and the contour of the projected 3D model
                    recover the different camera parameters
                    non-linear optimization algorithm like  Levenberg-Marquardt, simulated annealing, or the  downhill simplex method can be used
                    more efficient algorithm to calculate the  distance between silhouettes instead of contours.
                    projective texture  mapping 
                [tvcg] 2001 High-Quality Texture Reconstruction  from Multiple Scans
                    https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=965346
                [2008] Masked Photo Blending: mapping dense photographic dataset on 
                    high-resolution sampled 3D models
                [Burley2008] Ptex
                    https://people.cs.clemson.edu/~ekp/courses/dpa8090/assets/papers/Burley2008Ptex.pdf 
                    We propose a new texture mapping method for Catmull-Clark subdivision 
                        surfaces that requires no explicit parameterization
                    Supports Catmull-Clark subdivision surfaces (including quad and non-quad faces), Loop subdivision surfaces, and polymeshes (either all-quad or all-triangle).
                    a novel per-face adjacency map, in a single texture file per surface.
                    adjacency data
                    UV assignment
                    Catmull-Clark subdivision surfaces
                    procedural texture
                    painstaking manual setup
                    and no visible seams.
                    intrinsic per-face parameterization of the subdivision mesh
                    A key benefit of using the intrinsic parameterization is
                    the freedom from having to assign UVs before painting.
                    i'm free this evening
                    3Dçº¹ç†é‡å»º,è´´å›¾       
                [cg2008] Mapping dense photographic data set on high-resolution sampled 3D models
                    https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.169.8816&rep=rep1&type=pdf
                    high-resolution digital cameras
                    The problem is how to manage all this data to produce 3D models that could fit the interactive rendering constraints
                    texture synthesis
                    mesh parametrization
                    finding a parametrization for such  large meshes and managing such large textures can be prohibitive
                    colorimetric criteria
                    multivariate blending function
                    selectively mapped on the geometry
                    acquire  very dense sampling of both geometric and optical  surface properties of real objects
                    composed of millions of triangles
                    The resolution of digital camerasâ€™ CCD improved  also in an impressive manner
                    a significant overlap exists in those pixel dataset
                    recomputing the inverse projection
                    multi-resolution texture atlas
                [eccv14] Mvs-texturing
                    http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=17875004FACDF08081B04B2681B7FD1D?doi=10.1.1.431.7318&rep=rep1&type=pdf
                    https://www.gcc.tu-darmstadt.de/home/proj/texrecon/
                    https://github.com/nmoehrle/mvs-texturing
                    however, that  color information is still encoded as per-vertex color
                    and therefore coupled to  mesh resolution
                    a convincing experience for end users while keeping their size 
                        manageable is  still missing: texture
                    texturing 3D reconstructions 
                    texture acquisition
                    Still, they use  per-vertex colors and are therefore limited to the mesh resolution
                    limited to the mesh resolution
                    We argue that texture reconstruction is vitally important for creating realistic  models without increasing their geometric complexity
                    without increasing their geometric complexity
                    a practical method should be efficient enough to  handle even large models in a reasonable time frame
                    Texturing a 3D model from multiple registered images
                    a texture atlas (also called a sprite sheet or an image sprite) is an image containing multiple smaller images, usually packed together to reduce overall dimensions
                    A sub-image is drawn using custom texture coordinates to pick it out of the atlas.
                [cvpr18] G2LTex
                    https://yanqingan.github.io/docs/cvpr18_texture.pdf
                    https://github.com/fdp0525/G2LTex
                [tog17] FIELD-ALIGNED SURFACE RECONSTRUCTION
                    https://dl.acm.org/doi/pdf/10.1145/3072959.3073635
                    The  key property of our algorithm is that it sidesteps the signed-distance computation 
                        of classical reconstruction techniques in favor of direct filtering,  
                        parametrization, and mesh and texture extraction
                    final quality field-aligned textured mesh
                    displayed  in real-time to the user and can be easily resolved by adding further localized  scans
                    The final reconstructed, semiregular, and textured model is computed on-the-fly 
                        as new geometry is acquired.
                    The approximately linear cost of our reconstruction pipeline makes it ideal for large datasets.
                    clearly visible
                    approximate linear cost is clearly visible
                    equipped with a local parametrization, which is used for generating color and displacement maps
                    not guaranteed  to produce manifold output
                    or using  our hole-filling brush
                    We believe that this algorithm is  useful in contexts other than range scanning
                    reconstruction  of time varying datasets
                    the data is represented as an implicit surface or a CSG tree
                [cvpr2020] TextureFusion: High-Quality Texture Acquisition for Real-Time RGB-D Scanning
                    https://openaccess.thecvf.com/content_CVPR_2020/papers/Lee_TextureFusion_High-Quality_Texture_Acquisition_for_Real-Time_RGB-D_Scanning_CVPR_2020_paper.pdf
                    a progressive texture fusion  method, specially designed for real-time RGB-D scanning
                    surface geometry
                    camera pose
                    accumulating  the depth stream into a voxel grid of the truncated surface  distance function (TSDF)
                    camera pose for  each frame is estimated by the iterative closest point (ICP)
                    Color Per Voxel 
                    the quality of color information is often limited by  the long-lasting tradeoff between spatial resolution and time  performance
                    register texture to geometry
                    non-rigid texture optimization for real-time  RGB-D scanning.
                    Geometry update Texture update
                [siggraph17] Bundlefusion 
                    https://arxiv.org/pdf/1604.01093.pdf
                    transfered from vertex color to texture atlas, not real texture 

            stru:
                highlev
                    æ²¡æœ‰ä»€ä¹ˆç®—æ³•æ˜¯çœŸæ­£å®ç”¨åˆ°é€šåƒçš„, 3d Reconåº”ç”¨ç¯å¢ƒå¤šå˜
                        æœ‰çš„éœ€è¦å¥½çš„è§†è§‰æ•ˆæœï¼Œæœ‰çš„éœ€è¦å®æ—¶, æœ‰çš„éœ€è¦ä½æˆæœ¬ï¼Œæœ‰çš„éœ€è¦é«˜ç²¾åº¦çš„å‡ ä½•é‡å»ºã€‚
                        æœ‰çš„éœ€è¦å®Œæ•´åº¦ï¼Œæœ‰çš„åªéœ€è¦ä¸€ä¸ªè§†è§’ã€‚æœ‰çš„éœ€è¦ç‚¹äº‘ï¼Œæœ‰çš„éœ€è¦ç½‘æ ¼ï¼Œæœ‰çš„éœ€è¦å°é—­æ›²é¢ã€‚
                    sfmæ–¹æ³•æ¯”ç»“æ„å…‰æ›´æ–¹ä¾¿ï¼Œæ— éœ€äº‹å…ˆæ ‡å®šç›¸æœºï¼Œ
                        ä½†ç²¾åº¦å·®äº›ï¼Œç›®å‰å¾ˆå¤šç”¨æ— äººæœºå¯¹å¤§å‹å»ºç­‘å»ºæ¨¡å°±æ˜¯ç”¨çš„sfmæ–¹æ³•ã€‚
                    Tone the sfm acquisition
                        https://zhuanlan.zhihu.com/p/55636031
                    Assigning UVs traditionally has been the responsibility of the  Look Development department
                        creates the textures  and shaders that define the look of the models
                related work
                    Blending-based method
                        projected the captured images onto the surface of the geometric model according  to the intrinsic and extrinsic orientation parameters of the camera
                        suitable for processing close-range and small-range  models, such as indoor scenes and small objects
                        requires high calculation accuracy
                    Parameterization-based method
                        mapping the 3D  mesh model to the 2D texture image domain
                        computes the texture coordinate for each triangle face
                        This method generates small amounts of texture charts
                        but the 2D texture image domain is deformed  compared to the original image, which will inevitably cause the loss of texture information 
                            and is  not conducive to improving the texture reconstruction effect.
                    Projection-based method
                        projective texture mapping
                        Lempitsky et al. [28] first proposed to use the MRF energy function to select an optimal image for each triangle face
                        Yang et al. [31]  sampled the image sequence by using the spatio-temporal adaptive method. 
                
            mixed:
                https://groups.google.com/g/ptex
                http://threepark.net/slamdata/bedroom_loop_image_2/fusion_res.zip
                http://threepark.net
                http://pers.ge.imati.cnr.it/livesu/papers/Liv19/Liv19.pdf
                http://developer.download.nvidia.com/assets/gamedev/docs/RealtimePtex-siggraph2011.pdf
                https://www.gdcvault.com/play/1017757/Eliminating-Texture-Waste-Borderless-Realtime
                http://www.cs.ubc.ca/labs/imager/tr/2018/OptCuts/doc/OptCuts_small.pdf
                https://geometrycollective.github.io/boundary-first-flattening/  
                https://ptex.us/ptexpaper.html
                    Support arbitrary resolutions on a per-face basis
                https://developer.nvidia.com/siggraph-2011
            
    --- 
    meshes -> rendered pixels
        
        topic: neural rendering
            preview 
            approaches
                [2019] Deferred Neural Rendering: Image Synthesis using Neural Textures 
                    https://arxiv.org/abs/1904.12356
                    https://github.com/SSRSGJYD/NeuralTexture
                    https://github.com/A-Dying-Pig/OpenGL_NeuralTexture
                        with roughly the following steps:
                        1.install the zlib: https://github.com/horta/zlib.install
                        2.update the glfw repository under the "external" folder, the current one is corrupted
                            this can be done by cloning the https://github.com/glfw/glfw.git project 
                        3.generate a vs project with cmake, open the project as normal 
                        4.copy the *.fragmentshader and *.vertexshader files to the build directory 
                        5.change the output directory in main.cpp, line 41-43, set the output directories. Pay attention, 
                            one has to enlarge the file_name array if have a longer file name. 
                            (actually we have to modify it beacause the default size 10 is too small)
                        6.run the program 
            

            stru 

        topic: real time ray tracing 
            preview 
            approaches 
                Disney opensource 
                    * Disney Animation publications from academic journals and industry conferences.
                    * https://github.com/wdas
                    * https://github.com/wdas/ptex.git
                    * https://www.disneyanimation.com/data-sets/
                        https://wdas-datasets-disneyanimation-com.s3-us-west-2.amazonaws.com/moanaislandscene/island-basepackage-v1.1.tgz
                            This data set contains everything necessary to render 
                                a version of the Motunui island featured in the 2016 film Moana
                            Remove expensive, manual model unwrap step from art  pipeline
            stru 

    ---
    pointclouds -> rendered pixels 
        Fenek 
        Potree 

    ---
    application: very nice reconstructed model, vr ready 
        workflow old: projective texturing 
        
        workflow 16022021: *tobetransformed 
            1.lidar camera point cloud acquisition, best with camera positions -> .e57 file 
            -> 2.point cloud cleaning wiht software or coding libs eg. cloudcompare and pcl -> .txt file 
                may have to repare camera positions, include it into the scene 
                export unordered point cloud but with frames and campositions 
                fine clean with vr pc cleaner 
                currently only cloudcompare possible (prob. when exporting/ importing)
            3. .txt -> .e57 file with cam pose * (most hard one for we do not know how RC works actually, and familiar with .e57 file library)
                this is down with a customed version of CC, we should choose which cam pose to use and which 
                    verison of RC to be used as export 
            4.RealityCapture: recon + texturing -> obj with mtl 
            -> 5.simplify the generated mesh
            6.refine point cloud when needed -> 2 
            f: we shall continuesly simplify the workflow 
            f:
                - quality is limited to the meshing, we can improve the point clouds but not sure about their mesh quality 
                + good news is that it can 
            [personal]: p: realitycapture can not read unordered point cloud 
                quicktest: load a pcd -> e57 file to RC  
                a: modify the cloudcompare, to support ordered point cloud 
                    http://www.danielgm.net/cc/forum/viewtopic.php?t=2257
                    https://blog.csdn.net/cuglxw/article/details/75073820
                        ordered point cloud 
                        æœ‰åºç‚¹äº‘æŒ‰é¡ºåºæ’åˆ—ï¼Œå¯ä»¥å¾ˆå®¹æ˜“çš„æ‰¾åˆ°å®ƒçš„ç›¸é‚»ç‚¹ä¿¡æ¯ã€‚
                        æ— æ•ˆç‚¹ä¿¡æ¯ä¹Ÿæœ‰ç”¨ï¼Œå¯ä»¥é€šè¿‡å®ƒå¿«é€Ÿå‡†ç¡®çš„æ‰¾åˆ°ç‚¹äº‘è¾¹ç•Œã€‚
                        æœ‰åºç‚¹äº‘ä¸€èˆ¬æ˜¯åœ¨ç›¸æœºåæ ‡ç³»é‡Œçš„ï¼Œæ‰€ä»¥æ³•çº¿æ˜¯é¢å‘ç›¸æœºçš„ï¼Œæ‰€ä»¥æ³•çº¿å®šå‘é—®é¢˜è‡ªç„¶å°±è§£å†³äº†ã€‚
                        é¢œè‰²ä»£è¡¨äº†æ³•çº¿Zåˆ†é‡ã€‚æœ‰äº›æ‰«æä»ªåœ¨è¾¹ç•Œå¤„çš„è¯¯å·®æ¯”è¾ƒå¤§ï¼Œå¯ä»¥ç”¨è¿™ä¸ªæ–¹æ³•å¾ˆå¿«é€Ÿå‡†ç¡®çš„å»æ‰è¾¹ç•Œå¤„çš„ç‚¹ã€‚
                        æœ‰äº›ç‚¹æ˜¯æ— æ•ˆçš„ï¼Œä¸€èˆ¬ç”¨(0, 0, 0)æ¥ä»£æ›¿
                    https://zhuanlan.zhihu.com/p/34816510
                        æ¶‰åŠå…·ä½“æ•°æ®æ€ä¹ˆæ’åˆ—ï¼Œå‚è€ƒç®€åŒ–è¿‡ç¨‹
                ok 
            p: no campose after edit externally, not consistant! campose and cloud not match 
                a: change e57 header metadata/ entries
                    https://www.laserscanningforum.com/forum/viewtopic.php?t=15309
                    https://github.com/CloudCompare/CloudCompare/issues/665
                    not working, we can create groups but can not export 
                a: adjest campose in realitycapture? if e57 can not export correct positions  
                2d features seems not correct still  
                a: use py add pose node 
                    p: pointcloud changes! not clear how it did this 
                a: directly use c++ library?  
                    file:///C:/Users/yzhon/Downloads/E57SimpleImpl_doc-1.1.312/E57SimpleImpl_doc-1.1.312-x86-windows-mgw43/html/classe57_1_1_reader.html
                    https://github.com/ryanfb/e57tools/blob/master/src/e57validate.cpp
                    no simple example demostrates e57 file reading 
                a: modify CC directly 
                    https://github.com/CloudCompare/CloudCompare/blob/0dc77240911371e8d569ee3d9b97e84e8a249cf6/plugins/core/IO/qE57IO/src/E57Filter.cpp
                    OK 
                    but diff. version requires diff. format: older version requires ordered point cloud, which can not be read 
                    order point cloud supported 
                f: old version does not support 0 as position input! 
                f: do not extraction from e57 files (some restriction on workflow)
                f: adjest pose matrix and which version you want to use(old version can only support ordered pointcloud) ... 
                ok 
                p: can not use cloudcompare e57 plugin on other envs, missing xer....dll? seems not 
            
        workflow 18022021: 
            clean point clouds 
            best mesh 
            best images  
                p: image packing 
                    a: https://github.com/TeamHypersomnia/rectpack2D#windows
                        compile error c++20 
                    a: https://github.com/peterennis/Mosaic-1
                p: face selection 
                    a: with external tool: meshmixer 

